{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model1_final.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FG2511/MLP_ForFoodPreparation/blob/master/model1_risultati_Silvia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "hu-_5aP7LlL6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "75f43d60-f618-49f4-cf38-975f5f2d9273"
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "@File name: model1.ipynb\n",
        "@Created on 2018-12-20\n",
        "@Authors: Federica Gerina, Francesca Moi, Silvia Maria Massa\n",
        "@Description: Given a time-series dataset that contains minute-by-minute data \n",
        "about different kind of gases, collected by the uHoo air quality sensor, train\n",
        "a NN that classifies if a minute belongs to the class \"Pasto\" (1) otherwise to\n",
        "the class \"Other\" (0).\n",
        "'''\n",
        "\n",
        "!pip install liac-arff\n",
        "\n",
        "import arff\n",
        "import numpy as np\n",
        "from keras import optimizers\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.utils import compute_class_weight\n",
        "\n",
        "import sys\n",
        "sys.path.append('local_modules')\n",
        "\n",
        "import mlp\n",
        "import postprocessing_sw\n",
        "import cooking_inst_mod\n",
        "import utils\n",
        "\n",
        "#fix random seed for reproducibility\n",
        "seed = 5\n",
        "np.random.seed(seed)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: liac-arff in /usr/local/lib/python3.6/dist-packages (2.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "o99ibbgGHANE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        },
        "outputId": "7e693fd0-4a38-46a2-e973-edc8758e6c2d"
      },
      "cell_type": "code",
      "source": [
        "#@title CHOOSE\n",
        "\n",
        "'''\n",
        "@Description: MAIN\n",
        "'''\n",
        "\n",
        "#LOAD DATA\n",
        "print(\"Loading data...\")\n",
        "\n",
        "dataset = '/root/data/uHooComplete_featureDataset.arff' #@param {type:\"string\"}\n",
        "\n",
        "with open (dataset, encoding='utf-8') as f:\n",
        "  dataDictionary = arff.load(f)\n",
        "\n",
        "data = np.array(dataDictionary['data'])\n",
        "print(\"DATASET LOADED\")\n",
        "\n",
        "#CONVERTING VALUES\n",
        "print(\"\\nConverting values...\")\n",
        "for i in data:\n",
        "  if(i[-1] == 'Other'): i[-1] = 0\n",
        "  elif(i[-1] == 'Pasto') : i[-1] = 1\n",
        "\n",
        "dataset = data.astype('float32')\n",
        "print(\"CONVERSION DONE\")\n",
        "\n",
        "#SPLIT INTO INPUT (X) AND OUTPUT (Y) VARIABLES\n",
        "s = dataset.shape[-1]\n",
        "\n",
        "X = dataset[:,0:s-1]\n",
        "Y = dataset[:,s-1]\n",
        "\n",
        "n_features = s-1\n",
        "\n",
        "#SPLIT INTO TRAINING, VALIDATION AND TEST SETS\n",
        "print(\"\\nSplit into training, validation and test sets...\")\n",
        "\n",
        "train_rate = 80\n",
        "val_rate = 10\n",
        "train = round(int((dataset.shape[0]*train_rate)/100))\n",
        "val = round(int((dataset.shape[0]*(train_rate+val_rate))/100))\n",
        "\n",
        "train_data = X[:train]\n",
        "train_label = Y[:train]\n",
        "\n",
        "val_data = X[train+1:val]\n",
        "val_label = Y[train+1:val]\n",
        "\n",
        "test_data = X[val+1:]\n",
        "test_label = Y[val+1:]\n",
        "print(\"DATASET SPLITTED\")\n",
        "\n",
        "#COMPUTE CLASS WEIGHT\n",
        "labels = np.unique(train_label)\n",
        "classWeight = compute_class_weight('balanced', labels, train_label)\n",
        "classWeight = dict(zip(labels,classWeight))\n",
        "\n",
        "#GENERATE MODEL\n",
        "print(\"\\nGenerate model...\")\n",
        "model = mlp.generate_model_leaky(train_data.shape[-1], n_features)\n",
        "\n",
        "#OPTIMIZERS\n",
        "adm = optimizers.Adam(lr=0.0001)\n",
        "\n",
        "#COMPILE MODEL\n",
        "print(\"\\nCompile model...\")\n",
        "model.compile(loss='binary_crossentropy', optimizer = adm , metrics=['accuracy'])\n",
        "\n",
        "#EARLY STOPPING\n",
        "es = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
        "\n",
        "#FIT MODEL\n",
        "print(\"\\nFit model...\")\n",
        "history = model.fit(train_data, train_label, epochs=10, validation_data = (val_data, val_label), batch_size = 128, shuffle = True, class_weight = classWeight, verbose=1, callbacks = [es])\n",
        "\n",
        "#EVALUATE MODEL\n",
        "print(\"\\nEvaluate model...\")\n",
        "scores_test = model.evaluate(test_data, test_label, batch_size=128, verbose = 1)\n",
        "print(\"Test loss: %.2f%%\" % (scores_test[0] * 100))\n",
        "print(\"Test accuracy: %.2f%%\" % (scores_test[1] * 100))\n",
        "\n",
        "#CALCULATE PREDICTIONS\n",
        "print(\"\\nCalculate predictions...\")\n",
        "pred = model.predict_classes(test_data, batch_size=128, verbose=0)\n",
        "flat_pred = [item for sublist in pred for item in sublist]\n",
        "\n",
        "#CONFUSION MATRIX AND METRICS BEFORE POST PROCESSING\n",
        "print(\"\\n\\nCompute confusion matrix and metrics BEFORE POST PROCESSING...\")\n",
        "utils.compute_metrics(test_label, flat_pred)\n",
        "\n",
        "#STORE DATETIME\n",
        "time = []\n",
        "for i in test_data:\n",
        "  time.append(i[-5])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "DATASET LOADED\n",
            "\n",
            "Converting values...\n",
            "CONVERSION DONE\n",
            "\n",
            "Split into training, validation and test sets...\n",
            "DATASET SPLITTED\n",
            "\n",
            "Generate model...\n",
            "\n",
            "Compile model...\n",
            "\n",
            "Fit model...\n",
            "Train on 280392 samples, validate on 35048 samples\n",
            "Epoch 1/10\n",
            "280392/280392 [==============================] - 16s 57us/step - loss: 0.5404 - acc: 0.7602 - val_loss: 0.4588 - val_acc: 0.8491\n",
            "Epoch 2/10\n",
            "280392/280392 [==============================] - 14s 51us/step - loss: 0.4438 - acc: 0.8308 - val_loss: 0.4196 - val_acc: 0.8482\n",
            "Epoch 3/10\n",
            "280392/280392 [==============================] - 15s 52us/step - loss: 0.4136 - acc: 0.8321 - val_loss: 0.3685 - val_acc: 0.8523\n",
            "Epoch 4/10\n",
            "280392/280392 [==============================] - 14s 52us/step - loss: 0.3998 - acc: 0.8317 - val_loss: 0.3737 - val_acc: 0.8470\n",
            "Epoch 5/10\n",
            "280392/280392 [==============================] - 14s 52us/step - loss: 0.3934 - acc: 0.8289 - val_loss: 0.3619 - val_acc: 0.8506\n",
            "Epoch 6/10\n",
            "280392/280392 [==============================] - 14s 52us/step - loss: 0.3889 - acc: 0.8283 - val_loss: 0.3939 - val_acc: 0.8299\n",
            "Epoch 7/10\n",
            "280392/280392 [==============================] - 15s 52us/step - loss: 0.3822 - acc: 0.8281 - val_loss: 0.3598 - val_acc: 0.8530\n",
            "Epoch 8/10\n",
            "280392/280392 [==============================] - 15s 53us/step - loss: 0.3795 - acc: 0.8296 - val_loss: 0.4048 - val_acc: 0.8289\n",
            "Epoch 9/10\n",
            "280392/280392 [==============================] - 15s 52us/step - loss: 0.3725 - acc: 0.8300 - val_loss: 0.3862 - val_acc: 0.8281\n",
            "\n",
            "Evaluate model...\n",
            "35049/35049 [==============================] - 1s 17us/step\n",
            "Test loss: 51.51%\n",
            "Test accuracy: 79.16%\n",
            "\n",
            "Calculate predictions...\n",
            "\n",
            "\n",
            "Compute confusion matrix and metrics BEFORE POST PROCESSING...\n",
            "TN 25937\n",
            "FP 7044\n",
            "FN 259\n",
            "TP 1809\n",
            "ACCURACY: 79.16 %\n",
            "TRUE NEGATIVE RATE (SPECIFICITY): 78.64 %\n",
            "TRUE POSITIVE RATE (RECALL): 87.48 %\n",
            "PRECISION: 20.43 %\n",
            "F1 SCORE: 33.13 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "307NY4Yhukvv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "063472ca-c4fe-4987-91c8-8ef652e5fd73"
      },
      "cell_type": "code",
      "source": [
        "#CORRECTIONS: SETTING INSTANCES BETWEEN 01:00 am AND 05:00 am TO 0\n",
        "\n",
        "n_pred = []\n",
        "\n",
        "for p,t in zip(flat_pred, time):\n",
        "\n",
        "  if(t>59.0 and t<300.0):\n",
        "     n_pred.append(0)\n",
        "  else:\n",
        "    n_pred.append(p)\n",
        "\n",
        "print(\"\\n\\nCompute confusion matrix and metrics AFTER CORRECTIONS...\")\n",
        "utils.compute_metrics(test_label, n_pred)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Compute confusion matrix and metrics AFTER CORRECTIONS...\n",
            "TN 26214\n",
            "FP 6767\n",
            "FN 259\n",
            "TP 1809\n",
            "ACCURACY: 79.95 %\n",
            "TRUE NEGATIVE RATE (SPECIFICITY): 79.48 %\n",
            "TRUE POSITIVE RATE (RECALL): 87.48 %\n",
            "PRECISION: 21.09 %\n",
            "F1 SCORE: 33.99 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hdkk1t9J6oTb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "outputId": "18bd2e3c-a813-4fed-c891-8a4b4160ffc6"
      },
      "cell_type": "code",
      "source": [
        "#POST PROCESSING WITH SLIDING WINDOWS (MINUTE BY MINUTE)\n",
        "new_pred = postprocessing_sw.sliding_windows(flat_pred,35)\n",
        "new_pred_1 = postprocessing_sw.sliding_windows(n_pred,35)\n",
        "\n",
        "#CONFUSION MATRIX AND METRICS\n",
        "print(\"\\n\\nCompute NEW confusion matrix and metrics AFTER POST PROCESSING ONLY...\")\n",
        "utils.compute_metrics(test_label, new_pred)\n",
        "print(\"\\n\\nCompute confusion matrix and metrics AFTER CORRECTIONS AND POST PROCESSING...\")\n",
        "utils.compute_metrics(test_label, new_pred_1)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "SLIDING WINDOWS FUNCTION...\n",
            "\n",
            "SLIDING WINDOWS FUNCTION...\n",
            "\n",
            "\n",
            "Compute NEW confusion matrix and metrics AFTER POST PROCESSING ONLY...\n",
            "TN 26564\n",
            "FP 6417\n",
            "FN 281\n",
            "TP 1787\n",
            "ACCURACY: 80.89 %\n",
            "TRUE NEGATIVE RATE (SPECIFICITY): 80.54 %\n",
            "TRUE POSITIVE RATE (RECALL): 86.41 %\n",
            "PRECISION: 21.78 %\n",
            "F1 SCORE: 34.79 %\n",
            "\n",
            "\n",
            "Compute confusion matrix and metrics AFTER CORRECTIONS AND POST PROCESSING...\n",
            "TN 26839\n",
            "FP 6142\n",
            "FN 281\n",
            "TP 1787\n",
            "ACCURACY: 81.67 %\n",
            "TRUE NEGATIVE RATE (SPECIFICITY): 81.38 %\n",
            "TRUE POSITIVE RATE (RECALL): 86.41 %\n",
            "PRECISION: 22.54 %\n",
            "F1 SCORE: 35.75 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EHk6Ho1b1ZiQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        },
        "outputId": "a4835a4b-18ae-40b7-ac57-32e9a53c2591"
      },
      "cell_type": "code",
      "source": [
        "#COOKING INSTANCE MODALITY\n",
        "\n",
        "#before post-processing\n",
        "print(\"\\nCOOKING INSTANCE MODALITY BEFORE POST PROCESSING\")\n",
        "cooking_inst_mod.get_precision_recall_f1(flat_pred,test_label)\n",
        "#after corrections only\n",
        "print(\"\\nCOOKING INSTANCE MODALITY AFTER CORRECTIONS ONLY\")\n",
        "cooking_inst_mod.get_precision_recall_f1(n_pred,test_label)\n",
        "#after post-processing only\n",
        "print(\"\\nCOOKING INSTANCE MODALITY AFTER POST PROCESSING ONLY\")\n",
        "cooking_inst_mod.get_precision_recall_f1(new_pred,test_label)\n",
        "#after post-processing and corrections\n",
        "print(\"\\nCOOKING INSTANCE MODALITY AFTER CORRECTIONS AND POST PROCESSING\")\n",
        "cooking_inst_mod.get_precision_recall_f1(new_pred_1,test_label)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "COOKING INSTANCE MODALITY BEFORE POST PROCESSING\n",
            "N° pasti reali: 82\n",
            "N° pasti predetti: 216\n",
            "TP: 75\n",
            "FP: 134\n",
            "FN: 7\n",
            "Recall: 91.46 %\n",
            "Precision: 35.89 %\n",
            "F1 score: 51.55 %\n",
            "\n",
            "COOKING INSTANCE MODALITY AFTER CORRECTIONS ONLY\n",
            "N° pasti reali: 82\n",
            "N° pasti predetti: 210\n",
            "TP: 75\n",
            "FP: 128\n",
            "FN: 7\n",
            "Recall: 91.46 %\n",
            "Precision: 36.95 %\n",
            "F1 score: 52.63 %\n",
            "\n",
            "COOKING INSTANCE MODALITY AFTER POST PROCESSING ONLY\n",
            "N° pasti reali: 82\n",
            "N° pasti predetti: 123\n",
            "TP: 71\n",
            "FP: 55\n",
            "FN: 11\n",
            "Recall: 86.59 %\n",
            "Precision: 56.35 %\n",
            "F1 score: 68.27 %\n",
            "\n",
            "COOKING INSTANCE MODALITY AFTER CORRECTIONS AND POST PROCESSING\n",
            "N° pasti reali: 82\n",
            "N° pasti predetti: 118\n",
            "TP: 71\n",
            "FP: 50\n",
            "FN: 11\n",
            "Recall: 86.59 %\n",
            "Precision: 58.68 %\n",
            "F1 score: 69.95 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}